{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Access granted to Azure OpenAI in the desired Azure subscription. Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at https://aka.ms/oai/access. Open an issue on this repo to contact us if you have an issue.\n",
    "- Python 3.8 or later version.\n",
    "- An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. See [GPT-4 and GPT-4 Turbo Preview model availability](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-model-availability) for available regions. For more information about resource creation, see the [resource deployment guide](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource).\n",
    "\n",
    "- [Create a Speech resource](https://portal.azure.com/#create/Microsoft.CognitiveServicesSpeechServices) in the Azure portal.\n",
    "- Your Speech resource key and region. After your Speech resource is deployed, select Go to resource to view and manage keys. For more information about Azure AI services resources, see [Get the keys for your resource](https://learn.microsoft.com/en-us/azure/ai-services/multi-service-resource?pivots=azportal#get-the-keys-for-your-resource)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (1.30.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (2.7.2)\n",
      "Requirement already satisfied: sniffio in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.3)\n",
      "Requirement already satisfied: colorama in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------  41.0/42.0 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 675.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\isdev\\mystuff\\oz_ai\\sit788\\wk4\\azd-ml\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.9 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/798.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 102.4/798.9 kB 1.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 153.6/798.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 266.2/798.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 266.2/798.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 348.2/798.9 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 430.1/798.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 501.8/798.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 501.8/798.9 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 532.5/798.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 583.7/798.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 593.9/798.9 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 645.1/798.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 675.8/798.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 747.5/798.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/798.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.9/798.9 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp310-cp310-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 112.6/269.0 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 204.8/269.0 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  266.2/269.0 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n",
      "Collecting azure-cognitiveservices-speech\n",
      "  Downloading azure_cognitiveservices_speech-1.37.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Downloading azure_cognitiveservices_speech-1.37.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-cognitiveservices-speech\n",
      "Successfully installed azure-cognitiveservices-speech-1.37.0\n"
     ]
    }
   ],
   "source": [
    "! pip install openai\n",
    "! pip install tiktoken\n",
    "! pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    if image_path==\"\":\n",
    "        return \"\"\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_SPEECH=True #set this to true if you want to talk to the bot via speech\n",
    "OUT_SPEECH=True #set this to true if you want the bot to speak\n",
    "MAX_RESPONSE_TOKENS = 500\n",
    "TOKEN_LIMIT = 10000 # this is based on the model you use\n",
    "SPEECH_SERVICE_KEY=\"4b8cf2765b3c4401b3ceacef9bf0c9e0\"\n",
    "SPEECH_SERVICE_REGION=\"eastus\"\n",
    "AZURE_OPENAI_KEY=\"c19b9fc79d1647bb880e3422e560a649\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://oai23.openai.azure.com/\"\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=SPEECH_SERVICE_KEY, region=SPEECH_SERVICE_REGION)\n",
    "speech_config.speech_recognition_language=\"en-US\"\n",
    "speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = AZURE_OPENAI_KEY,  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello how can I help you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is the color of the car\n",
      "\n",
      "AI: The car in the image is primarily white.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m conversation\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello how can I help you today?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     data_url\u001b[38;5;241m=\u001b[39mlocal_image_to_data_url(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQ: Please enter the image URL otherwise press enter.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m IN_SPEECH:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeak into your microphone.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ISDEV\\mystuff\\OZ_AI\\SIT788\\WK4\\azd-ml\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ISDEV\\mystuff\\OZ_AI\\SIT788\\WK4\\azd-ml\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "conversation = []\n",
    "conversation.append(system_message)\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-4-0125-Preview-0314\"): # this is based on the model you use\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-0125-Preview-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-0125-Preview-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            if type(value)==list:\n",
    "                continue\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "print(\"AI: \" + \"Hello how can I help you today?\\n\")\n",
    "conversation.append({\"role\": \"assistant\", \"content\": \"Hello how can I help you today?\"})\n",
    "while True:\n",
    "    data_url=local_image_to_data_url(input(\"Q: Please enter the image URL otherwise press enter.\"))\n",
    "    if IN_SPEECH:\n",
    "        print(\"Speak into your microphone.\")\n",
    "        user_input = speech_recognizer.recognize_once_async().get().text\n",
    "    else:\n",
    "        user_input = input(\"Q:\")\n",
    "        \n",
    "    print(\"User: \" + user_input + \"\\n\")\n",
    "    \n",
    "    if data_url==\"\":\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    else:\n",
    "        conversation.append({\"role\": \"user\", \"content\": [{\"type\": \"text\",\"text\": user_input},{\"type\": \"image_url\",\"image_url\": {\"url\": data_url}}]})\n",
    "\n",
    "    conv_history_tokens = num_tokens_from_messages(conversation)\n",
    "\n",
    "    while conv_history_tokens + MAX_RESPONSE_TOKENS >= TOKEN_LIMIT:\n",
    "        del conversation[1] \n",
    "        conv_history_tokens = num_tokens_from_messages(conversation)\n",
    "    \n",
    "    if OUT_SPEECH:\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt40\", #depending on your deployment name\n",
    "        messages=conversation,\n",
    "        max_tokens=MAX_RESPONSE_TOKENS\n",
    "        )\n",
    "        \n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        speech_synthesizer.speak_text_async(response.choices[0].message.content).get()\n",
    "        print(\"AI: \" + response.choices[0].message.content + \"\\n\")\n",
    "        \n",
    "    else:\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt40\", #depending on your deployment name\n",
    "            messages=conversation,\n",
    "            stream=True,\n",
    "            max_tokens=MAX_RESPONSE_TOKENS\n",
    "        )\n",
    "        \n",
    "        full_message=\"\"\n",
    "        print(\"AI: \",end=\"\")\n",
    "        for chunk in response:\n",
    "            if hasattr(chunk, 'choices') and len(chunk.choices) > 0:\n",
    "                if hasattr(chunk.choices[0].delta, 'content'):\n",
    "                    content_chunk = chunk.choices[0].delta.content\n",
    "                    if content_chunk:  # Check if content_chunk is not None\n",
    "                        print(content_chunk, end=\"\")  # Print partial response\n",
    "                        full_message += content_chunk\n",
    "        print(\"\\n\")\n",
    "        response=full_message\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": full_message})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
